--------------SLIDE 1--------------
Hello everybody, my name is Pepijn and for the last couple months I have been
working on my thesis called 'AI-drive retrieval and analysis of videotaped
council meeting archives using automatic speech recognition, speaker identification
and retrieval augmented generation'. This is a whole mouthful, so let's break it
down a bit.
--------------SLIDE 2--------------
The core of the thesis involves videotaped council meeting archives. These are
large collections of long videos, with the videos being videotaped government
meetings. The problem with these videos, is that searching for specific information
is difficult. These meetings can easily be 3 to 4 hours long, so searching for
specifc information within can be a hard task.
--------------SLIDE 3--------------
So, I created an AI based tool capable of retrieving specifc information from these
large video archives. Meaning, I made these video archives searchable in a Google-
like manner so you are able to find specifc information quickly in a multi-hour long
video. On top of this, I used a relatively new technique called retrieval augmented
generation to create a conversational style chat bot capable of answering specifc
questions about a specifc video.
--------------SLIDE 4--------------
This retrieval is made possible by the AI driven analysis performed on the archived
videos. The main pieces of analysis done, is the automatic speech recognition, meaning
the video audio is converted to written text. And teh speaker identification, meaning
different speakers are distinguished, along with the times at which they are speaking.
--------------SLIDE 5--------------
So, to make the problem and solution at hand more clear, lets say you want to look
for the answer to the following question: 'What are the expected advantages to the
installation of the gardens surrounding underground trash containers?'.
--------------DEMO--------------
http://localhost:5173/#/gemeente/ridderkerk/vergaderingen/2022/986115
Currently, you would have to go to the video and either watch the whole thing, or
skim through the video, hoping you do not skip the specific part in the video that
contains the answer. In this case, the video is only 35 minutes, so it is not that
bad. You can imagine however, that doing the same with a video of 4 hours is a
difficult task.

--------------SLIDE 7--------------
So to briefly summorize how I solved the problem of the difficulty of searching
for specifc information through long video archives, I firstly created a archiving
tool that will scrape video meeting and the agenda points. Next, these videos are
automatically analysed in two different manners: speech to text and speaker segmentation.
These analysed videos are then made searchable with a transcript search engine, and a
conversational style chat bot. All these functionalities are then combined into an easily
navigable web application.
--------------SLIDE 8--------------
The global architecture looks something like this: As you can see, it receives as
input a government, the years that you want archived and the meeting types, and it
uses one of two developed scraping tools to archive the whole collection. Together,
the two hosting providers that the scraper supports host the vast majority of Dutch
municipalites.
After scraping, the videos are analysed.
--------------SLIDE 9--------------
The analysis consists of two parts: speech to text and speaker recognition. Both
are done with current state-of-the-art AI models, and they are combined to make
searching as optimal as possible.
Then, the different speakers recognised by pyannote will have their voice profiles
embedded. These voice profiles can then be manually named one time, after which they
are able to be recognized in any video.
Finally, all this information is added to a central database allowing for searching
in the gathered data.
--------------SLIDE 10--------------
The analysis pipeline looks like this: a video first is transcribed and diarised.
the speaker recognition and speech to text is then combined to create uninterrupted
speaking turns, which is how the database is indexed. At the same time, the different
speakers have their voice profile analysed and the speaking turn along with the voice
profile are combined and added to the database. On the side, you can see the manual
labeling of voice profiles and their addition to the database.
--------------SLIDE 11--------------
Finally, the search part offers three different search methods: an AI-based semantic
search, a probability based keyword search, a combination of the two, and a
conversational style chat bot.

In order to verify whether or not the solution actually works, I gave 13 participants
the task to answer five questions in the five different manners, with the method and
question randomly assigned. If an answer could not be found within three minutes, it
counted as a miss and the search was aborted.
--------------SLIDE 12--------------
This gave me the following results. As you can see, the contemporary method of skimming
through the video performed the worse by far. On average, the answer was found in about
two minutes. However, in almost 70% of the cases an answer was not found withing the
given time. The three search methods performed roughly equal, at around 30 to 40 seconds
with a 0% miss rate.
The chat mode scored the best, with about 20 seconds search time. Note however, that in
23% of the cases an answer was not found at all. On top of this, I found that the chat
method could be quite unreliably at some times. The way it works is that before answering
a question, the context most relevant to the query is retrieved and fed to the AI model.
When it occurs that the context is not the desired context, or when no context could be
found at all, the chat bot will either give a wrong answer, without you knowing, or it could
tell you it does not know. This is why, it is recommended to verify the answer after getting
one. This verfication time was not included in this test however.
--------------SLIDE 13--------------
To summorize briefly: This project aims at solving the difficulty of searching
through large video archives, specifically those of governemntal meetings.
To solve this, I created an automatic scraping tool, capable of scraping the two
biggest meeting hosting services in the Netherlands.
After archiving, video analysis is done, transcribing and diarising the videos.
These transcripts are then made searchable using semantic- and keyword search.
Finally, a conversational style chat bot has been developed capable of answering
questions given. This all is then packaged in an easy to use web application.

Thank you for listening are there any questions?
